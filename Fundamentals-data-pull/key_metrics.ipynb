{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: pip: command not found\n",
      "/bin/bash: pip: command not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickwarner/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas-gbq\n",
    "!pip install yfinance\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import requests\n",
    "import json \n",
    "import csv\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import io\n",
    "#from google.cloud import bigquery\n",
    "#from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Manually load list of tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AMZN', 'INTC', 'LRCX', 'META', 'BABA', 'GIS', 'KMI', 'KO', 'MCD', 'MDT', 'MMM', 'TEL', 'USB', 'XYL', 'URNM', 'ABNB', 'AMAT', 'ASML', 'KLAC', 'KLIC', 'MRAM', 'SWKS', 'UROY', 'VMFXX', 'BWXT', 'DOCS', 'SPOT', 'SILXY', 'CLLNY', 'SRUUF', 'YLLXF', 'IGN', 'VGT', 'VUG', 'SOXX', 'VONG', 'JEPI', 'SCHD', 'VB', 'VIG', 'VTI', 'FXAIX', 'SPAXX', 'VXUS', 'TWCGX', 'SPY', 'EMCLOUD', 'COMP', 'FROG', 'MCHP', 'IRDM', 'NVEC', 'MXL', 'OPRA', 'BELFB', 'EXTR', 'IDCC', 'ON', 'HLIT', 'PLAB', 'VEEV', 'TTD', 'SHOP', 'CDLX', 'ZI', 'DV', 'S', 'ZS', 'CRWD', 'ADSK', 'PANW', 'MSI', 'ANET', 'EQIX', 'EGIO', 'DOCN', 'NET', 'RKLB', 'ASTS', 'COIN', 'NCNO', 'FISV', 'ENPH', 'TOELY', 'QRVO', 'BESI', 'VSH', 'AEHR', 'TXN', 'SLAB', 'CRUS', 'NXPI', 'AVGO', 'MPWR', 'LSCC', 'SNPS', 'CDNS', 'APH', 'CGNX', 'PLPC', 'SYM', 'IOT', 'TMO', 'DHR', 'TT', 'IRM', 'SEIC', 'NOW', 'BDC', 'DIOD', 'JBL', 'CARG', 'CSGS', 'ADBE', 'CRM', 'NOW', 'SHOP', 'WDAY', 'PYPL', 'SNOW', 'CRWD', 'TEAM', 'DDOG', 'SQ', 'MDB', 'VEEV', 'ZS', 'HUBS', 'NET', 'ZM', 'OKTA', 'TWLO', 'PAYC', 'PATH', 'DBX', 'PCTY', 'DOCU', 'TOST', 'ESTC', 'PCOR', 'APPF', 'GTLB', 'MNDY', 'QLYS', 'BILL', 'SMAR', 'CFLT', 'FRSH', 'WIX', 'ZI', 'WK', 'S', 'FIVN', 'BRZE', 'TENB', 'ASAN', 'SQSP', 'CXM', 'CWAN', 'BOX', 'BL', 'NCNO', 'AI', 'SPT', 'FROG', 'RNG', 'DOCN', 'FSLY', 'PD', 'QTWO', 'AVDX', 'AVPT', 'AMPL', 'ZUO', 'EVBG', 'DH', 'YEXT', 'OLO', 'BIGC', 'VMEO', 'WEAV', 'EGHT', 'DOMO', 'NOVT', 'IPGP', 'COHR', 'GFS', 'MU', 'WOLF', 'TXN', 'INTC', 'NVDA', 'ADI', 'QCOM', 'NXPI', 'TER', 'ALGM', 'MRVL', 'SWKS', 'ASML', 'AMD', 'MPWR', 'ON', 'LSCC', 'QRVO', 'AVGO', 'MCHP', 'AMAT', 'LRCX', 'ENTG', 'KLAC', 'TSM', 'SYNA', 'MKL']\n"
     ]
    }
   ],
   "source": [
    "data = '''AMZN\n",
    "INTC\n",
    "LRCX\n",
    "META\n",
    "BABA\n",
    "GIS\n",
    "KMI\n",
    "KO\n",
    "MCD\n",
    "MDT\n",
    "MMM\n",
    "TEL\n",
    "USB\n",
    "XYL\n",
    "URNM\n",
    "ABNB\n",
    "AMAT\n",
    "ASML\n",
    "KLAC\n",
    "KLIC\n",
    "MRAM\n",
    "SWKS\n",
    "UROY\n",
    "VMFXX\n",
    "BWXT\n",
    "DOCS\n",
    "SPOT\n",
    "SILXY\n",
    "CLLNY\n",
    "SRUUF\n",
    "YLLXF\n",
    "IGN\n",
    "VGT\n",
    "VUG\n",
    "SOXX\n",
    "VONG\n",
    "JEPI\n",
    "SCHD\n",
    "VB\n",
    "VIG\n",
    "VTI\n",
    "FXAIX\n",
    "SPAXX\n",
    "VXUS\n",
    "TWCGX\n",
    "SPY\n",
    "EMCLOUD\n",
    "COMP\n",
    "FROG\n",
    "MCHP\n",
    "IRDM\n",
    "NVEC\n",
    "MXL\n",
    "OPRA\n",
    "BELFB\n",
    "EXTR\n",
    "IDCC\n",
    "ON\n",
    "HLIT\n",
    "PLAB\n",
    "VEEV\n",
    "TTD\n",
    "SHOP\n",
    "CDLX\n",
    "ZI\n",
    "DV\n",
    "S\n",
    "ZS\n",
    "CRWD\n",
    "ADSK\n",
    "PANW\n",
    "MSI\n",
    "ANET\n",
    "EQIX\n",
    "EGIO\n",
    "DOCN\n",
    "NET\n",
    "RKLB\n",
    "ASTS\n",
    "COIN\n",
    "NCNO\n",
    "FISV\n",
    "ENPH\n",
    "TOELY\n",
    "QRVO\n",
    "BESI\n",
    "VSH\n",
    "AEHR\n",
    "TXN\n",
    "SLAB\n",
    "CRUS\n",
    "NXPI\n",
    "AVGO\n",
    "MPWR\n",
    "LSCC\n",
    "SNPS\n",
    "CDNS\n",
    "APH\n",
    "CGNX\n",
    "PLPC\n",
    "SYM\n",
    "IOT\n",
    "TMO\n",
    "DHR\n",
    "TT\n",
    "IRM\n",
    "SEIC\n",
    "NOW\n",
    "BDC\n",
    "DIOD\n",
    "JBL\n",
    "CARG\n",
    "CSGS\n",
    "ADBE\n",
    "CRM\n",
    "NOW\n",
    "SHOP\n",
    "WDAY\n",
    "PYPL\n",
    "SNOW\n",
    "CRWD\n",
    "TEAM\n",
    "DDOG\n",
    "SQ\n",
    "MDB\n",
    "VEEV\n",
    "ZS\n",
    "HUBS\n",
    "NET\n",
    "ZM\n",
    "OKTA\n",
    "TWLO\n",
    "PAYC\n",
    "PATH\n",
    "DBX\n",
    "PCTY\n",
    "DOCU\n",
    "TOST\n",
    "ESTC\n",
    "PCOR\n",
    "APPF\n",
    "GTLB\n",
    "MNDY\n",
    "QLYS\n",
    "BILL\n",
    "SMAR\n",
    "CFLT\n",
    "FRSH\n",
    "WIX\n",
    "ZI\n",
    "WK\n",
    "S\n",
    "FIVN\n",
    "BRZE\n",
    "TENB\n",
    "ASAN\n",
    "SQSP\n",
    "CXM\n",
    "CWAN\n",
    "BOX\n",
    "BL\n",
    "NCNO\n",
    "AI\n",
    "SPT\n",
    "FROG\n",
    "RNG\n",
    "DOCN\n",
    "FSLY\n",
    "PD\n",
    "QTWO\n",
    "AVDX\n",
    "AVPT\n",
    "AMPL\n",
    "ZUO\n",
    "EVBG\n",
    "DH\n",
    "YEXT\n",
    "OLO\n",
    "BIGC\n",
    "VMEO\n",
    "WEAV\n",
    "EGHT\n",
    "DOMO\n",
    "NOVT\n",
    "IPGP\n",
    "COHR\n",
    "GFS\n",
    "MU\n",
    "WOLF\n",
    "TXN\n",
    "INTC\n",
    "NVDA\n",
    "ADI\n",
    "QCOM\n",
    "NXPI\n",
    "TER\n",
    "ALGM\n",
    "MRVL\n",
    "SWKS\n",
    "ASML\n",
    "AMD\n",
    "MPWR\n",
    "ON\n",
    "LSCC\n",
    "QRVO\n",
    "AVGO\n",
    "MCHP\n",
    "AMAT\n",
    "LRCX\n",
    "ENTG\n",
    "KLAC\n",
    "TSM\n",
    "SYNA\n",
    "MKL'''\n",
    "\n",
    "tickers = data.split('\\n')\n",
    "print(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full Year Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ticker_dataframes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/nickwarner/Documents/GitHub/public-stock-market-data/Fundamentals-data-pull/key_metrics.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nickwarner/Documents/GitHub/public-stock-market-data/Fundamentals-data-pull/key_metrics.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mTicker\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m ticker\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nickwarner/Documents/GitHub/public-stock-market-data/Fundamentals-data-pull/key_metrics.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m# store the dataframe in the ticker_dataframes dictionary with the ticker as the key\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nickwarner/Documents/GitHub/public-stock-market-data/Fundamentals-data-pull/key_metrics.ipynb#W4sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     ticker_dataframes[ticker] \u001b[39m=\u001b[39m df\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nickwarner/Documents/GitHub/public-stock-market-data/Fundamentals-data-pull/key_metrics.ipynb#W4sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# concatenate all dataframes into one\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nickwarner/Documents/GitHub/public-stock-market-data/Fundamentals-data-pull/key_metrics.ipynb#W4sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m combined_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(ticker_dataframes\u001b[39m.\u001b[39mvalues(), ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ticker_dataframes' is not defined"
     ]
    }
   ],
   "source": [
    "# set the API endpoint URL with a placeholder for the ticker\n",
    "url_template = \"https://fmpcloud.io/api/v3/key-metrics/{}?datatype=csv&apikey=a726d5acabd86910ef2749315f5eaa86\"\n",
    "\n",
    "# define a list of tickers\n",
    "tickers = tickers\n",
    "\n",
    "# loop over the tickers and make an API request for each one\n",
    "for ticker in tickers:\n",
    "    # replace the placeholder with the current ticker\n",
    "    url = url_template.format(ticker)\n",
    "\n",
    "    # make an HTTP GET request to the API endpoint and retrieve the data in CSV format\n",
    "    response = requests.get(url)\n",
    "    data = response.text\n",
    "\n",
    "    # create a dataframe from the data\n",
    "    df = pd.read_csv(io.StringIO(data))\n",
    "\n",
    "    # add a new column to the dataframe with the ticker symbol\n",
    "    df['Ticker'] = ticker\n",
    "\n",
    "    # store the dataframe in the ticker_dataframes dictionary with the ticker as the key\n",
    "    ticker_dataframes[ticker] = df\n",
    "\n",
    "# concatenate all dataframes into one\n",
    "combined_df = pd.concat(ticker_dataframes.values(), ignore_index=True)\n",
    "\n",
    "# save the combined dataframe as a CSV file\n",
    "combined_df.to_csv(\"metricsFY.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file using pandas\n",
    "df = pd.read_csv('metricsFY.csv')\n",
    "\n",
    "# Define the DW table columns\n",
    "desired_columns = [\n",
    "    \"symbol\",\n",
    "    \"date\",\n",
    "    \"period\",\n",
    "    \"revenuePerShare\",\n",
    "    \"netIncomePerShare\",\n",
    "    \"operatingCashFlowPerShare\",\n",
    "    \"freeCashFlowPerShare\",\n",
    "    \"cashPerShare\",\n",
    "    \"bookValuePerShare\",\n",
    "    \"tangibleBookValuePerShare\",\n",
    "    \"peRatio\",\n",
    "    \"priceToSalesRatio\",\n",
    "    \"pfcfRatio\",\n",
    "    \"pbRatio\",\n",
    "    \"evToSales\",\n",
    "    \"evToOperatingCashFlow\",\n",
    "    \"evToFreeCashFlow\",\n",
    "    \"freeCashFlowYield\",\n",
    "    \"debtToEquity\",\n",
    "    \"debtToAssets\",\n",
    "    \"currentRatio\",\n",
    "    \"dividendYield\",\n",
    "    \"salesGeneralAndAdministrativeToRevenue\",\n",
    "    \"researchAndDdevelopementToRevenue\",\n",
    "    \"intangiblesToTotalAssets\",\n",
    "    \"capexToOperatingCashFlow\",\n",
    "    \"capexToRevenue\",\n",
    "    \"stockBasedCompensationToRevenue\",\n",
    "    \"roic\",\n",
    "    \"returnOnTangibleAssets\",\n",
    "    \"averageInventory\",\n",
    "    \"daysSalesOutstanding\",\n",
    "    \"daysOfInventoryOnHand\",\n",
    "    \"inventoryTurnover\",\n",
    "    \"roe\",\n",
    "    \"capexPerShare\"\n",
    "]\n",
    "\n",
    "# Keep only the desired columns\n",
    "df = df[desired_columns]\n",
    "\n",
    "# Save the resulting DataFrame to a new CSV file\n",
    "df.to_csv('metricsFY.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "key_metrics = pd.read_csv('metricsFY.csv')\n",
    "\n",
    "\n",
    "# Handle Non-finite Values:\n",
    "key_metrics['averageInventory'] = key_metrics['averageInventory'].fillna(0).astype(int)\n",
    "key_metrics['daysSalesOutstanding'] = key_metrics['daysSalesOutstanding'].fillna(0).astype(int)\n",
    "key_metrics['daysOfInventoryOnHand'] = key_metrics['daysOfInventoryOnHand'].fillna(0).astype(int)\n",
    "\n",
    "\n",
    "# Explicitly set the 'DATE' column as datetime64[ns]\n",
    "key_metrics = pd.DataFrame({\n",
    "    'SYMBOL': key_metrics['symbol'].astype(str),\n",
    "    'DATE': pd.to_datetime(key_metrics['date'], errors='coerce'),\n",
    "    'PERIOD': key_metrics['period'].astype(str),\n",
    "    'REVENUEPERSHARE': key_metrics['revenuePerShare'].astype(float),\n",
    "    'NETINCOMEPERSHARE': key_metrics['netIncomePerShare'].astype(float),\n",
    "    'OPERATINGCASHFLOWPERSHARE': key_metrics['operatingCashFlowPerShare'].astype(float),\n",
    "    'FREECASHFLOWPERSHARE': key_metrics['freeCashFlowPerShare'].astype(float),\n",
    "    'CASHPERSHARE': key_metrics['cashPerShare'].astype(float),\n",
    "    'BOOKVALUEPERSHARE': key_metrics['bookValuePerShare'].astype(float),\n",
    "    'TANGIBLEBOOKVALUEPERSHARE': key_metrics['tangibleBookValuePerShare'].astype(float),\n",
    "    'PERATIO': key_metrics['peRatio'].astype(float),\n",
    "    'PRICETOSALESRATIO': key_metrics['priceToSalesRatio'].astype(float),\n",
    "    'PFCFRATIO': key_metrics['pfcfRatio'].astype(float),\n",
    "    'PBRATIO': key_metrics['pbRatio'].astype(float),\n",
    "    'EVTOSALES': key_metrics['evToSales'].astype(float),\n",
    "    'EVTOOPERATINGCASHFLOW': key_metrics['evToOperatingCashFlow'].astype(float),\n",
    "    'EVTOFREECASHFLOW': key_metrics['evToFreeCashFlow'].astype(float),\n",
    "    'FREECASHFLOWYIELD': key_metrics['freeCashFlowYield'].astype(float),\n",
    "    'DEBTTOEQUITY': key_metrics['debtToEquity'].astype(float),\n",
    "    'DEBTTOASSETS': key_metrics['debtToAssets'].astype(float),\n",
    "    'CURRENTRATIO': key_metrics['currentRatio'].astype(float),\n",
    "    'DIVIDENDYIELD': key_metrics['dividendYield'].astype(float),\n",
    "    'SALESGENERALANDADMINISTRATIVETOREVENUE': key_metrics['salesGeneralAndAdministrativeToRevenue'].astype(float),\n",
    "    'RESEARCHANDDEVELOPMENTTOREVENUE': key_metrics['researchAndDdevelopementToRevenue'].astype(float),\n",
    "    'INTANGIBLESTOTOTALASSETS': key_metrics['intangiblesToTotalAssets'].astype(float),\n",
    "    'CAPEXTOOPERATINGCASHFLOW': key_metrics['capexToOperatingCashFlow'].astype(float),\n",
    "    'CAPEXTOREVENUE': key_metrics['capexToRevenue'].astype(float),\n",
    "    'STOCKBASEDCOMPENSATIONTOREVENUE': key_metrics['stockBasedCompensationToRevenue'].astype(float),\n",
    "    'ROIC': key_metrics['roic'].astype(float),\n",
    "    'RETURNONTANGIBLEASSETS': key_metrics['returnOnTangibleAssets'].astype(float),\n",
    "    'AVERAGEINVENTORY': key_metrics['averageInventory'].astype(int),\n",
    "    'DAYSSALESOUTSTANDING': key_metrics['daysSalesOutstanding'].astype(int),\n",
    "    'DAYSOFINVENTORYONHAND': key_metrics['daysOfInventoryOnHand'].astype(int),\n",
    "    'INVENTORYTURNOVER': key_metrics['inventoryTurnover'].astype(float),\n",
    "    'ROE': key_metrics['roe'].astype(float),\n",
    "    'CAPEXPERSHARE': key_metrics['capexPerShare'].astype(float),\n",
    "})\n",
    "\n",
    "# Check if the column exists before renaming\n",
    "old_column_name = 'researchAndDdevelopementToRevenue'\n",
    "new_column_name = 'researchAndDevelopementToRevenue'\n",
    "\n",
    "if old_column_name in key_metrics.columns:\n",
    "    key_metrics.rename(columns={old_column_name: new_column_name}, inplace=True)\n",
    "\n",
    "\n",
    "key_metrics.columns = key_metrics.columns.str.upper()\n",
    "\n",
    "\n",
    "project_id = 'stock-market-data-391622'\n",
    "dataset_id = 'market_information'\n",
    "table_name = 'key_metrics'\n",
    "\n",
    "\n",
    "# Create a BigQuery client with service account credentials\n",
    "credentials = service_account.Credentials.from_service_account_file('stock-market-data-391622-03ee9e592be9.json')\n",
    "client = bigquery.Client(credentials=credentials, project=project_id)\n",
    "\n",
    "# Specify the destination table in BigQuery\n",
    "destination_table = 'stock-market-data-391622.market_information.key_metrics'\n",
    "\n",
    "\n",
    "# Write the DataFrame to BigQuery without specifying the schema\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    write_disposition=\"WRITE_APPEND\",  # Options: \"WRITE_TRUNCATE\", \"WRITE_APPEND\", \"WRITE_EMPTY\", \"WRITE_TRUNCATE\"\n",
    ")\n",
    "\n",
    "\n",
    "client.load_table_from_dataframe(\n",
    "    key_metrics, destination_table, job_config=job_config\n",
    ").result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = 'bcfff2f4-59a3-4e04-ae8e-2611f539f067'  # Replace with new job ID\n",
    "job = client.get_job(job_id)\n",
    "print(job.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quarterly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the API endpoint URL with a placeholder for the ticker\n",
    "url_template = \"https://fmpcloud.io/api/v3/key-metrics/{}?datatype=csv&period=quarter&apikey=a726d5acabd86910ef2749315f5eaa86\"\n",
    "\n",
    "# define a list of tickers\n",
    "tickers = tickers\n",
    "\n",
    "# loop over the tickers and make an API request for each one\n",
    "for ticker in tickers:\n",
    "    # replace the placeholder with the current ticker\n",
    "    url = url_template.format(ticker)\n",
    "\n",
    "    # make an HTTP GET request to the API endpoint and retrieve the data in CSV format\n",
    "    response = requests.get(url)\n",
    "    data = response.text\n",
    "\n",
    "    # create a dataframe from the data\n",
    "    df = pd.read_csv(io.StringIO(data))\n",
    "\n",
    "    # add a new column to the dataframe with the ticker symbol\n",
    "    df['Ticker'] = ticker\n",
    "\n",
    "    # store the dataframe in the ticker_dataframes dictionary with the ticker as the key\n",
    "    ticker_dataframes[ticker] = df\n",
    "\n",
    "# concatenate all dataframes into one\n",
    "combined_df = pd.concat(ticker_dataframes.values(), ignore_index=True)\n",
    "\n",
    "# save the combined dataframe as a CSV file\n",
    "combined_df.to_csv(\"metrics_quarterly.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file using pandas\n",
    "df = pd.read_csv('metrics_quarterly.csv')\n",
    "\n",
    "# Define the DW table columns\n",
    "desired_columns = [\n",
    "    \"symbol\",\n",
    "    \"date\",\n",
    "    \"period\",\n",
    "    \"revenuePerShare\",\n",
    "    \"netIncomePerShare\",\n",
    "    \"operatingCashFlowPerShare\",\n",
    "    \"freeCashFlowPerShare\",\n",
    "    \"cashPerShare\",\n",
    "    \"bookValuePerShare\",\n",
    "    \"tangibleBookValuePerShare\",\n",
    "    \"peRatio\",\n",
    "    \"priceToSalesRatio\",\n",
    "    \"pfcfRatio\",\n",
    "    \"pbRatio\",\n",
    "    \"evToSales\",\n",
    "    \"evToOperatingCashFlow\",\n",
    "    \"evToFreeCashFlow\",\n",
    "    \"freeCashFlowYield\",\n",
    "    \"debtToEquity\",\n",
    "    \"debtToAssets\",\n",
    "    \"currentRatio\",\n",
    "    \"dividendYield\",\n",
    "    \"salesGeneralAndAdministrativeToRevenue\",\n",
    "    \"researchAndDdevelopementToRevenue\",\n",
    "    \"intangiblesToTotalAssets\",\n",
    "    \"capexToOperatingCashFlow\",\n",
    "    \"capexToRevenue\",\n",
    "    \"stockBasedCompensationToRevenue\",\n",
    "    \"roic\",\n",
    "    \"returnOnTangibleAssets\",\n",
    "    \"averageInventory\",\n",
    "    \"daysSalesOutstanding\",\n",
    "    \"daysOfInventoryOnHand\",\n",
    "    \"inventoryTurnover\",\n",
    "    \"roe\",\n",
    "    \"capexPerShare\"\n",
    "]\n",
    "\n",
    "# Keep only the desired columns\n",
    "df = df[desired_columns]\n",
    "\n",
    "# Save the resulting DataFrame to a new CSV file\n",
    "df.to_csv('metrics_quarterly.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "key_metrics = pd.read_csv('metrics_quarterly.csv')\n",
    "\n",
    "\n",
    "# Handle Non-finite Values:\n",
    "key_metrics['averageInventory'] = key_metrics['averageInventory'].fillna(0).astype(int)\n",
    "key_metrics['daysSalesOutstanding'] = key_metrics['daysSalesOutstanding'].fillna(0).astype(int)\n",
    "key_metrics['daysOfInventoryOnHand'] = key_metrics['daysOfInventoryOnHand'].fillna(0).astype(int)\n",
    "\n",
    "\n",
    "# Explicitly set the 'DATE' column as datetime64[ns]\n",
    "key_metrics = pd.DataFrame({\n",
    "    'SYMBOL': key_metrics['symbol'].astype(str),\n",
    "    'DATE': pd.to_datetime(key_metrics['date'], errors='coerce'),\n",
    "    'PERIOD': key_metrics['period'].astype(str),\n",
    "    'REVENUEPERSHARE': key_metrics['revenuePerShare'].astype(float),\n",
    "    'NETINCOMEPERSHARE': key_metrics['netIncomePerShare'].astype(float),\n",
    "    'OPERATINGCASHFLOWPERSHARE': key_metrics['operatingCashFlowPerShare'].astype(float),\n",
    "    'FREECASHFLOWPERSHARE': key_metrics['freeCashFlowPerShare'].astype(float),\n",
    "    'CASHPERSHARE': key_metrics['cashPerShare'].astype(float),\n",
    "    'BOOKVALUEPERSHARE': key_metrics['bookValuePerShare'].astype(float),\n",
    "    'TANGIBLEBOOKVALUEPERSHARE': key_metrics['tangibleBookValuePerShare'].astype(float),\n",
    "    'PERATIO': key_metrics['peRatio'].astype(float),\n",
    "    'PRICETOSALESRATIO': key_metrics['priceToSalesRatio'].astype(float),\n",
    "    'PFCFRATIO': key_metrics['pfcfRatio'].astype(float),\n",
    "    'PBRATIO': key_metrics['pbRatio'].astype(float),\n",
    "    'EVTOSALES': key_metrics['evToSales'].astype(float),\n",
    "    'EVTOOPERATINGCASHFLOW': key_metrics['evToOperatingCashFlow'].astype(float),\n",
    "    'EVTOFREECASHFLOW': key_metrics['evToFreeCashFlow'].astype(float),\n",
    "    'FREECASHFLOWYIELD': key_metrics['freeCashFlowYield'].astype(float),\n",
    "    'DEBTTOEQUITY': key_metrics['debtToEquity'].astype(float),\n",
    "    'DEBTTOASSETS': key_metrics['debtToAssets'].astype(float),\n",
    "    'CURRENTRATIO': key_metrics['currentRatio'].astype(float),\n",
    "    'DIVIDENDYIELD': key_metrics['dividendYield'].astype(float),\n",
    "    'SALESGENERALANDADMINISTRATIVETOREVENUE': key_metrics['salesGeneralAndAdministrativeToRevenue'].astype(float),\n",
    "    'RESEARCHANDDEVELOPMENTTOREVENUE': key_metrics['researchAndDdevelopementToRevenue'].astype(float),\n",
    "    'INTANGIBLESTOTOTALASSETS': key_metrics['intangiblesToTotalAssets'].astype(float),\n",
    "    'CAPEXTOOPERATINGCASHFLOW': key_metrics['capexToOperatingCashFlow'].astype(float),\n",
    "    'CAPEXTOREVENUE': key_metrics['capexToRevenue'].astype(float),\n",
    "    'STOCKBASEDCOMPENSATIONTOREVENUE': key_metrics['stockBasedCompensationToRevenue'].astype(float),\n",
    "    'ROIC': key_metrics['roic'].astype(float),\n",
    "    'RETURNONTANGIBLEASSETS': key_metrics['returnOnTangibleAssets'].astype(float),\n",
    "    'AVERAGEINVENTORY': key_metrics['averageInventory'].astype(int),\n",
    "    'DAYSSALESOUTSTANDING': key_metrics['daysSalesOutstanding'].astype(int),\n",
    "    'DAYSOFINVENTORYONHAND': key_metrics['daysOfInventoryOnHand'].astype(int),\n",
    "    'INVENTORYTURNOVER': key_metrics['inventoryTurnover'].astype(float),\n",
    "    'ROE': key_metrics['roe'].astype(float),\n",
    "    'CAPEXPERSHARE': key_metrics['capexPerShare'].astype(float),\n",
    "})\n",
    "\n",
    "# Check if the column exists before renaming\n",
    "old_column_name = 'researchAndDdevelopementToRevenue'\n",
    "new_column_name = 'researchAndDevelopementToRevenue'\n",
    "\n",
    "if old_column_name in key_metrics.columns:\n",
    "    key_metrics.rename(columns={old_column_name: new_column_name}, inplace=True)\n",
    "\n",
    "\n",
    "key_metrics.columns = key_metrics.columns.str.upper()\n",
    "\n",
    "\n",
    "project_id = 'stock-market-data-391622'\n",
    "dataset_id = 'market_information'\n",
    "table_name = 'key_metrics'\n",
    "\n",
    "\n",
    "# Create a BigQuery client with service account credentials\n",
    "credentials = service_account.Credentials.from_service_account_file('stock-market-data-391622-03ee9e592be9.json')\n",
    "client = bigquery.Client(credentials=credentials, project=project_id)\n",
    "\n",
    "# Specify the destination table in BigQuery\n",
    "destination_table = 'stock-market-data-391622.market_information.key_metrics'\n",
    "\n",
    "\n",
    "# Write the DataFrame to BigQuery without specifying the schema\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    write_disposition=\"WRITE_APPEND\",  # Options: \"WRITE_TRUNCATE\", \"WRITE_APPEND\", \"WRITE_EMPTY\", \"WRITE_TRUNCATE\"\n",
    ")\n",
    "\n",
    "\n",
    "client.load_table_from_dataframe(\n",
    "    key_metrics, destination_table, job_config=job_config\n",
    ").result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = '75193c05-ec54-4697-9925-e9dd8c731de8'  # Replace with new job ID\n",
    "job = client.get_job(job_id)\n",
    "print(job.state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
